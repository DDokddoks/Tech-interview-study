# Operating System

### ⚡️ Chapter 1-2. Introduction & OS Stuructures

- 운영체제란 무엇인가?

  > 운영체제(Operating System)는 컴퓨터 시스템(하드웨어)을 운영 및 관리하는 항상 실행 중인 시스템 소프트웨어(프로그램)이다. 응용 프로그램을 위한 기반(system service)을 제공하며 프로세스 및 자원을 관리하고, 컴퓨터 사용자와 컴퓨터 하드웨어 사이에서 중재자 역할을 하면서 사용자가 하드웨어를 직접 조작하는 것을 방지한다.

- 운영체제의 주요 목적은?

  > 운영체제는 컴퓨터 시스템 자원(CPU, Memory 등)을 효율적으로 관리해 **시스템 효율성**을 높이는 목적과 컴퓨터 시스템을 사용자로 하여금 편리하게 사용하도록 지원하는 **사용자 편의성**의 목적을 가진다.

- 커널이란 무엇인가?

  > 운영체제의 핵심으로 항상 메모리에 상주하는 운영체제의 부분을 커널이라고 한다.

- 부팅이 되는 과정은?

  > 1. 컴퓨터의 전원이 켜지면 Boot-ROM에 저장되어 있는 Bootstrap Program이 실행
  > 2. 컴퓨터 시스템 하드웨어 초기화
  > 3. HDD에서 OS 프로그램을 MM의 첫번째 자리에 로드하여 OS 실행
  > 4. 운영체제 프로그램 실행 시작

- 시스템 콜에 대해 설명하세요

  > System Call은 운영체제의 커널이 제공하는 서비스를 이용하기 위해 응용 프로그램의 요청에 따라 커널에 접근하기 위한 인터페이스이다. 운영체제는 커널모드(Kernel Mode)와 사용자모드(User Mode)로 나뉘어 구동되는데, 시스템 콜은 이러한 커널 영역의 기능을 사용자 모드가 사용 가능하게 한다.

- 멀티프로세싱 vs 멀티프로그래밍 vs 멀티태스킹 vs 멀티쓰레딩

  > - 멀티 프로세싱(Multi-processing) : 다수의 프로세서(CPU)가 다수의 프로세스를 서로 병렬적으로 처리하는 것, **프로그램을 더 빨리 처리하기 위함**이 목적
  > - 멀티 프로그래밍(Multi-programming) : 단일 프로세서(CPU)가 다수의 프로세스가 동시에 처리하는 것, **CPU의 활용도를 최대화**하기 위함이 목적
  > - 멀티 태스킹(Multi-tasking) : 다수의 작업(task)을 운영체제 스케줄링에 의해 번갈아가면서 처리하는 것, 사용자에게 **다수의 작업이 동시에 처리되는 것처럼 느끼게** 할 수 있다.
  > - 멀티 쓰레딩(Multi-threading) : 다수의 스레드가 하나의 프로세스를 구성하여 서로 자원을 공유하는 것, **자원을 효율적으로 사용하여 작업 처리 속도를 향상**시키는 것

- 메모리 계층 구조의 순서가 어떻게 되는가? CPU에서 가까운 순으로 말해보시오.

  > <img src="https://user-images.githubusercontent.com/68578916/175803000-38af3f0d-8ddb-4a29-8aa7-78fa3ccb33a9.png" width="500" />

### ⚡️ Chapter 3. Processes

- Heap과 Stack의 차이점은 무엇인가요?

  > Heap
  >
  > - 동적 메모리가 저장되는 영역
  > - 사용자가 직접 관리할 수 있고, '그리고 관리를 해야만 하는' 메모리 영역이다.
  > - 메모리의 낮은 주소에서 높은 주소의 방향으로 할당된다.
  >
  > Stack
  >
  > - 정적 메모리가 저장되는 영역
  > - 함수의 호출과 함께 할당되며, 함수의 호출이 완료되면 소멸한다.
  > - 메모리의 높은 주소에서 낮은 주소의 방향으로 할당된다.

- 프로세스에 할당되는 메모리의 각 영역에 대해서 설명해 주세요.

  > - **Text** : Code 혹은 Instruction 영역이라고도 하며, 컴파일된 프로그램 코드가 저장되어 있다. 고정 크기이다.
  > - **Data** : 전역 변수를 저장하고 있는 영역이다. 고정 크기이다.
  > - **Heap** : 프로그램의 런타임 중에 동적으로 할당되는 메모리가 저장되는 영역이다. 가변 크기이다.
  > - **Stack** : 함수 호출 시 함수 파라미터, return 주소, 지역 변수 등 임시 데이터의 저장장소이다. 가변 크기이다.

- 프로세스와 그 특징에 대해 설명하세요.

  > 프로세스는 실행 중인 프로그램으로 운영체제에서 작업의 단위이다.
  > 프로세스는 4가지의 영역(text, stack, data, heap)으로 구분된다.
  > 프로세스는 5가지 상태 (New, Running, Waiting, Ready, Terminated) 를 가진다.
  > 각 프로세스의 정보는 PCB에 저장된다.

- 프로세스가 종료되는 2가지 경우를 설명하세요.

  > 프로세스가 마지막 명령을 수행하거나 exit() 시스템 콜을 호출하였을 때 스스로 종료한다.
  > 프로세스가 다른 프로세스를 종료시키는 경우에 부모가 자식들 중 하나의 실행을 종료할 수 있다.
  >
  > - 경우1. 자식이 자신에게 할당된 자원을 초과하여 사용할 때
  > - 경우2. 자식에게 할당된 태스크가 더 이상 필요없을 때
  > - 경우3. 부모가 exit를 하는데, 운영체제는 부모가 exit한 후에 자식이 실행을 계속하는 것을 허용하지 않는경우. (cascading termination(연쇄식 종료))

- 인터럽트 발생 및 처리과정을 설명하세요.

  > 프로그램 실행 중 인터럽트가 발생하면 프로그램을 중단하고 현 프로그램 상태를 보관하기 위한 context switching 작업이 진행된다. 그 후 인터럽트 번호를 읽고 해당 번호를 인터럽트 벡터의 인덱스로 사용하여 ISR 주소값으로 점프하고, 인터럽트 서비스 루틴을 처리한다. 해당 작업을 다 처리하면, 보관했던 레지스터를 복원한 후 인터럽트를 해제하고 이전 실행 위치로 PC 값이 복원된다.

- 인터럽트 기능이 없다면 사용하는 방식에 대해 설명하세요.

  > 인터럽트 기능이 없다면 CPU는 어떤 일을 할 시기를 알기 위해 디바이스 상태를 계속 체크해야 하며, 이를 **폴링(Polling)** 이라고 한다.인터럽트 방식에 비해 구현이 간편하다는 장점이 있지만 다른 프로그램이나 장치들 간의 폴링이 많아질수록 CPU 사용량이 늘어나 성능이 크게 떨어지게 되며, 폴링의 주기가 길어질수록 반응 속도가 늦어져 실시간성이 떨어진다는 단점이 있다.

- 프로세스의 생성 과정에 대해 설명해보세요.

  > 1. 생성된 새로운 프로세스에 프로세스 id를 할당한다.
  > 2. 프로세스의 모든 구성 요소를 포함할 수 있는 주소 공간과 PCB 공간을 할당한다.
  > 3. PCB를 초기화한다. 프로그램의 코드는 Text 영역, 초기화된 전역/static 변수는 Data 영역에 저장되며 Heap과 Stack 영역은 초기 메모리 주소만 초기화된다. 그 외에 프로세스의 상태 정보, 프로그램 카운터, 우선순위 등이 초기화된다.
  > 4. PCB에 여러 정보가 기록되면 Ready Queue에서 CPU를 할당받기를 대기한다.

- IPC 방식에 대해 설명하세요.

  > IPC의 방식에는 Shared Memory 방식과 Message Passing 방식 두 가지가 있다.    
  > **Shared Memory** 방식은 둘 이상의 프로세스가 공유하는 메모리 영역을 두고 해당 메모리 영역에 데이터를 채우거나 소비하는 등 변경하는 데이터를 공유하는 방식으로 통신한다.  
  > **Message Passing** 방식은 프로세스 간의 메시지를 주고 받는 방식으로 (send, receive) 이때 커널이 메시지를 전달해주며 관리한다. 크게 direct, indrect 통신으로 구분된다.  
  >
  > - direct 통신은 수신인과 발신인을 명시하고 소통하는 두 프로세스 사이에 자동으로 하나의 링크가 생성된다.  
  > - indirect 통신은 수신인과 발신인을 명시하지 않아도 되고, 메시지들을 mailbox나 port를 통해서 주고 받는다. 각 프로세스가 공유 mailbox를 가지고 있는 경우 링크가 생성되고, 링크는 2개 이상의 프로세스와 연결될 수 있다.

- Context Switching이란 무엇인가요?

  > 어떤 프로세스를 실행하고 있는 상태에서 인터럽트에 의해 다른 프로세스가 실행되어야 할 때, 기존의 프로세스 정보들은 PCB에 저장하고 다음 프로세스의 정보를 PCB에서 가져와 교체하는 작업을 컨텍스트 스위칭이라 한다.

- 동기와 비동기, 블로킹과 넌블로킹의 차이는 무엇인가요?

  > 동기와 비동기는 프로세스의 수행 순서 보장에 대한 매커니즘이고 블록킹과 논블록킹은 프로세스의 유휴 상태에 대한 개념으로 완전한 별개의 개념이라는 것이다.
  >
  > - 동기 & 비동기
  >   - 처리해야 할 작업들을 어떠한 '흐름'으로 처리 할 것인가에 대한 관점
  >   - 즉, 호출되는 함수의 작업 완료 여부를 신경쓰냐에 따라, 함수 실행/리턴 순차적인 흐름을 따르느냐, 안따르느냐 관심사
  >   - 동기
  >     - 호출하는 함수 A가 호출되는 함수 B의 작업 완료 후 리턴을 기다리거나, 바로 리턴 받더라도 미완료 상태이라면 작업 완료 여부를 스스로 계속 확인하며 신경쓰면 Synchronous (작업을 동시에 수행하거나, 동시에 끝나거나, 끝나는 동시에 시작)
  >   - 비동기
  >     - 함수 A가 함수 B를 호출할 때 콜백 함수를 함께 전달해서, 함수 B의 작업이 완료되면 함께 보낸 콜백 함수를 실행한다.
  >     - 함수 A는 함수 B를 호출한 후로 함수 B의 작업 완료 여부에는 신경쓰지 않는다. Asynchronous (시작, 종료가 일치하지 않으며, 끝나는 동시에 시작을 하지 않음)
  > - 블로킹 & 논블로킹
  >   - 처리되어야 하는 (하나의) 작업이, 전체적인 작업 '흐름'을 막느냐 안막느냐에 대한 관점
  >   - 즉, 제어권이 누구한테 있느냐가 관심사
  >   - Blocking
  >     - A 함수가 B 함수를 호출하면, 제어권을 A가 호출한 B 함수에 넘겨준다. (자신의 작업을 진행하다가 다른 주체의 작업이 시작되면 다른 작업이 끝날 때까지 기다렸다가 자신의 작업을 시작하는 것)
  >   - Non-Blocking
  >     - A 함수가 B 함수를 호출해도 제어권은 그대로 자신이 가지고 있는다. (다른 주체의 작업에 관련없이 자신의 작업을 하는 것)

- 프로세스 제어블록에는 어떤 정보가 담겨있나요?
  
  > (1) Process ID : 프로세스를 구분하는 ID  
(2) Process State : 각 State 들의 상태를 저장한다.  
(3) Program Counter : 다음 Instruction 의 주소를 저장하는 카운터. CPU는 이 값을 통해 Process 의 Instruction 을 수행한다.  
(4) Register : Accumulator, CPU Register, General Register 등을 포함한다.  
(5) CPU Scheduling Information : 우선 순위, 최종 실행시간, CPU 점유시간 등이 포함된다.  
(6) Memory Information : 해당 프로세스 주소공간(lower bound ~ upper bound) 정보를 저장.  
(7) Process Information(페이지 테이블, 스케줄링 큐 포인터, 소유자, 부모 등)  
(8) Device I/O Status(프로세스에 할당된 입출력 장치 목록, 열린 팔린 목록 등)  
(9) Pointer : 부모/자식 프로세스에 대한 포인터, 자원에 대한 포인터 등   
(10) Open File List : 프로세스를 위해 열려있는 파일의 리스트  

- child process, orphan process, zombie process에 대해 설명해 보시오.

  > **child process** : 부모 프로세스가 fork() 시스템 콜을 호출하면서 만들어진 프로세스로 부모의 프로세스의 복제 프로세스이다.  
  > **orphan process** : parent process가 wait()을 호출하지 않고 자식 프로세스보다 먼저 종료해버린 경우에 child process가 완전히 종료되지 못하고 남아있게 되는데 이때 child process를 orphan process라고 한다.  
  > **zombie process** : 자신은 종료되었지만, parent process가 아직 wait()를 호출하지 않은 상태일 때의 child process를 의미한다. 모든 프로세스는 아주 짧은 시간이나마 zombie process 상태를 머무르게 된다. zombie process를 활용하여 daemon process(background process)를 만들 때 쓰이기도 한다.  

### ⚡️ Chapter 4. Thread

- 프로세스와 쓰레드의 차이를 설명해보세요

  > 프로세스는 운영체제로부터 할당받는 작업의 단위(실행 중인 프로그램)이고, 스레드는 할당 받은 자원을 이용하는 실행 단위이다. 프로세스는 독립적인 메모리 영역을 할당받지만 스레드는 스택을 제외한 나머지 공간을 공유한다.

- 크롬 탭이 프로세스인지 쓰레드인지 설명해보세요

  > 크롬은 탭마다 PID를 가지고 있으니 Process이며 각 Tab마다 랜더링 정보나 기타 데이터를 따로 관리한다. 이로 인해 메모리를 많이 잡아먹기도 하지만 하나의 Tab에 오류가 생겼다고 모든 Tab에 영향을 끼치진 않는다.

- 멀티 프로세스와 멀티 스레드 각각의 장단점

  > - 멀티 프로세스  
  >   - 장점  
  >     • 각 프로세스가 독립된 영역(code, data, stack, heap)을 갖고 있기 때문에 여러 자식 프로세스 중 하나에 문제가 발생해도 해당 프로세스에만 영향을 미친다.  
  >     • 메모리 침범 문제를 OS 차원에서 해결하므로 안전하다.  
  >   - 단점  
  >     • 작업량이 많아지면 context switching 시 오버헤드가 발생한다.  
  >     • 프로세스 간의 복잡한 통신(IPC)가 필요하다.  

  > - 멀티 스레드  
  >   - 장점  
  >     • 메모리 공간, 시스템 자원의 효율성이 증가한다.  
  >     • context switching 시 교환해야 할 대상이 적으므로 비용이 적다.  
  >     • data, heap 영역을 이용해 데이터를 주고 받으므로 스레드 간 통신이 간단하다.  
  >   - 단점  
  >     • 서로 다른 스레드가 Stack을 제외한 메모리 공간을 공유하기 때문에 동기화 문제가 발생할 수 있다.  
  >     • 스레드 간의 자원 공유는 전역 변수(data segment)를 이용하므로 다른 스레드가 동시에 사용할 때 충돌이 발생할 수 있다.  
  >     • 하나의 스레드에 문제가 생기면 전체 스레드가 영향을 받는다.  
  >     • 주의 깊은 설계가 필요하며 디버깅이 까다롭다.  
  >     • 멀티 스레드의 단점은 critical section 기법을 통해 대비할 수 있다.  

- 멀티 프로세스 대신 멀티 스레드를 사용하는 이유는 무엇입니까?

  > - Responsiveness(응답성)
  >   - 프로세스의 일부가 block 되어도, 지속적인 실행이 가능함
  > - Resource Sharing(자원 공유)
  >   - 프로세스의 자원을 공유하여 shared memory와 message passing보다 용이
  > - Economy(경제)
  >   - 프로세스 생성보다 효율적
  >   - 스레드 스위칭이 context switching보다 오버헤드가 적음
  > - Scalability(확장성)
  >   - 각 프로세스들을 thread 단위로 분할하여 실행함으로써 multiprocessor 구조에서 더 큰 이점을 얻을 수 있음

- 사용자 수준의 스레드와 커널 수준의 스레드의 차이는 무엇인가요?

  > - **User threads**
  >   - user mode에서 사용되는 thread
  >   - kernel 위에서 kernel support 없이 관리
  >   - OS가 가진 CPU들을 자유롭게 사용할 수는 없음
  > - **kernel threads**
  >   - kernel mode에서 사용되는 thread
  >   - OS가 직접 관리 및 지원
  >   - OS가 가진 CPU들을 자유롭게 사용할 수 있음

- 스레드 풀링이란 무엇이고 장점은?

  > - Thread Pools
  >   - 프로세스를 시작할 때 아예 일정한 수의 thread들을 미리 풀로 만들어 두는 것
  >   - 매번 사용되고 바로 폐기되는 스레드를 새로 생성하는 것은 시간 낭비
  >   - 개수의 한계 없이 모든 요청에서 새 스레드를 생성하면 CPU 시간, 메모리 공간 등 자원이 고갈될 수 있기 때문
  > - 장점
  >   - 새 스레드를 만들어 주기보다 기존 스레드로 서비스해 주는 것이 종종 더 빠르다.
  >   - 스레드 풀은 임의 시각에 존재할 스레드 개수에 제한을 둔다. 이러한 제한은 많은 수의 스레드를 병렬 처리할 수 없는 시스템에 도움이 된다.
  >   - 태스크를 생성하는 방법을 태스크로부터 분리하면 태스크를 실행을 다르게 할 수 있다. 예를 들어 태스크를 일정 시간 후에 실행되도록 스케줄 하거나 혹은 주기적으로 실행시킬 수 있다.

### ⚡️ Chapter 5. CPU Scheduling

- CPU 스케줄링이란 무엇인가요?

  > CPU 스케줄링이란 프로세스가 작업을 수행할 때, 언제 어떤 프로세스에 CPU를 할당할지를 결정하는 방법으로 CPU를 효율적으로 사용할 수 있도록 한다.

- CPU Scheduling은 언제 발생하는가?

  > CPU 스케줄링은 네 가지 상태에서 발생할 수 있다.
  >
  > 1. **Running → Waiting(Blocked)** : I/O 요청이나 자식의 종료를 위해 wait( ) 함수 호출한 경우
  > 2. **Running → Ready** : 인터럽트가 발생한 경우
  > 3. **Waiting → Ready** : I/O 작업이 끝난 경우
  > 4. **Terminate**
  >    이때, 비선점형 스케줄링은 1과 4의 경우일 때 스케줄링이 발생하지만, 선점형 스케줄링은 1,2,3,4 모두에서 발생 가능하다.

- CPU 스케줄링 종류와 방법에는 대표적으로 어떤 것들이 있나요?

  > - **FCFS(First-Come First-Served) Scheduling**
  >   CPU를 먼저 요청한 프로세스 순서대로 먼저 CPU를 할당받는 비선점형 알고리즘이다.
  > - **SJF(Shortest-Job-First) Scheduling**
  >   CPU burst time이 가장 짧은 프로세스에게 먼저 CPU를 할당해주는 알고리즘 방식으로 Preemptive / Non-preemptive 모두 가능하다. 이때 선점형 SJF 방식은 SRTF라 하며 최소의 평균 대기 시간(optimal)을 보장하지만, starvation 현상이 발생할 수 있다.
  > - **Priority Scheduling**
  >   각 프로세스에 우선순위를 부여하고, 가장 높은 우선순위를 가진 프로세스에 CPU를 할당하는 방식으로 Preemptive / Non-preemptive 모두 가능하다. 이때도 기아(starvation) 현상이 발생할 수 있는데 에이징(aging) 기법으로 해결 가능하다.
  > - **RR(Round-Robin) Scheduling**
  >   각 프로세스에는 일정한 할당시간(time quantum)동안 CPU를 사용하고 할당 시간이 지나면 선점당하고 다시 ready queue로 들어가는 선점형 스케줄링 알고리즘이다. RR 스케줄링의 성능은 quantum 값에 따라 달라지는데, 해당 값이 너무 커지면 FCFS가 되고, 반대로 너무 작아지면 불필요한 context switching이 많이 발생해 오버헤드가 커진다.
  > - **Multilevel Queue**
  >   Ready queue를 여러 개로 분할하고, 각 큐는 독립적인 스케줄링 알고리즘(Intra-Queue Scheduling)을 갖게 되며, 큐들 사이에도 스케줄링(Inter-Queue Scheduling)이 이루어진다.
  > - **Multilevel Feedback Queue**
  >   MLQ에서 한 프로세스는 영구적으로 특정 큐에 할당되어 다른 큐로 이동하지 못하는 것과 달리, 프로세스가 큐들 사이를 이동할 수 있는 알고리즘이다. 이때 CPU burst의 성격에 따라 어느 큐에 들어갈지를 구분한다. (I/O bound process에 가까울수록 높은 우선순위)

- Starvation이란?

  > 계속해서 우선순위가 높은 프로세스가 새로 들어오면서, 상대적으로 우선순위가 낮은 프로세스가 CPU를 계속 할당받지 못하고 무한으로 대기하는 상태를 의미한다.

- Aging이란?

  > Starvation Problem의 해결방안으로, 시간이 지날수록 프로세스의 우선순위를 점진적으로 높이는 방식이다. 따라서 모든 프로세스는 언젠가 가장 높은 우선순위를 가지게 되므로 무한 대기가 발생하지 않는다.

- Preemptive Scheduling과 Non-preemptive Scheduling의 차이점?

  > - Preemptive Scheduling : CPU 스케줄러가 CPU를 선점하고 있는 프로세스를 중단시키고 다른 프로세스에게 CPU를 할당하는 방법이다.
  > - Non-preemptive Scheduling : 프로세스가 한번 CPU를 선점하면 프로세스가 block(wait) 상태로 바뀌거나 실행이 끝났을 때만 다른 프로세스로 CPU를 할당 가능하고, Preemptive Scheduling과 달리 지연되는 경우가 있어 응답시간이 평균적으로 길다.

### ⚡️ Chapter 6. Process Synchronization

- 경쟁 상태(Race Condition)란 무엇인가요?

  > 경쟁 상태(Race condition)는 Multi-processor system에서 두 개 이상의 프로세스나 스레드가 동시에 공유 데이터에 접근하는 상황을 의미한다. Data inconsistency 문제가 발생할 수 있다. consistency 유지를 위해 협력 프로세스 간의 실행 순서를 정해주는 '동기화'가 필요하다.

- 임계영역 문제에 대한 해결책에는 어떤 것들이 있나요?

  > 먼저, 임계영역 문제를 해결하기 위한 조건에는 Mutual exclusion(상호 배제), Progress(진행), Bounded waiting(한정된 대기) 3가지가 있다. 이를 만족하는 동기화 알고리즘으로 Peterson's Algorithm이 있고, 구현을 간편하게 하기 위한 방법으로 Semaphore가 있다. 추가로, 이와 달리 lock을 사용하지 않는 Monitor 방식이 있다.

  > **Peterson's Algorithm**
  > 임계영역 진입 의사를 표시하기 위한 변수 flag와 각 프로세스의 진입 가능 여부를 판단하기 위한 변수 turn을 사용하여, 두 개의 프로세스가 동시에 임계영역에 접근할 수 없게 한다. 상대방의 flag가 true이고, turn도 상대방인 경우에만 기다린다.

  > **Semaphore**
  > 자원의 개수를 저장하는 변수 S와 공유 데이터를 획득하거나 획득할 수 없으면 대기하는 과정의 P연산, 공유 데이터를 반납하는 과정의 V연산을 이용하여 critical section에 들어가기 전에는 P연산, 나올 때는 V연산을 수행하여 프로세스가 동시에 critical section에 접근할 수 없게 한다.
  > 크게 두 가지 방식으로 구분된다.
  >
  > - Binary Semaphore(=Mutex) : 0과 1 값만을 이용한다.
  > - Counting semaphore : 0 이상의 정수값을 가질 수 있는 counter를 두어 동시에 리소스에 접근할 수 있는 허용 가능한 프로세스나 스레드의 수를 제어한다.

  > **Monitor**
  > Monitor란 동시 수행 중인 프로세스 사이에서 abstract data type의 안전한 공유를 보장하기 위한 high-level synchronization construct이다. Monitor는 공유하는 변수와 그 변수를 조작할 수 있는 사용자 정의 opertaion(프로시저 or 함수)을 포함하며, Monitor 내의 operation은 원천적으로 동시에 여러 개가 실행될 수 없도록 설계되어 있어 세마포어와 달리 프로그래머가 따로 lock을 해줄 필요 없이 race condition을 해결할 수 있다.

- 프로세스 혹은 스레드의 동기화란 무엇인가요?

  > Race condition에서 하나의 자원을 동시에 여러 개의 프로세스나 스레드가 접근하지 못하도록 제어함으로써 Data inconsistency 방지를 위한 방법이다.

- thread-safe의 의미?

  > 멀티 스레드 프로그래밍에서 일반적으로 어떤 함수나 변수, 혹은 객체가 여러 스레드로부터 동시에 접근이 이루어져도 프로그램의 실행에 무리가 없음을 의미한다. Thread-safe하게 구현하기 위해서는 공유 자원에 접근하는 임계영역(critical section)을 동기화 기법으로 제어해줘야 한다(상호배제).

- 락을 걸지 않고 경쟁상태를 해결할 수 있는 방법은 무엇인가요?

  > Monitor를 사용하는 것이다. Monitor는 공유하는 변수와 그 변수를 조작할 수 있는 사용자 정의 operation(프로시저 or 함수)을 포함하며, Monitor 내의 operation은 원천적으로 동시에 여러 개가 실행될 수 없도록 설계되어 있어 프로그래머가 따로 lock을 해줄 필요 없이 racing condition을 해결할 수 있다.

### ⚡️ Chapter 7. Deadlocks

- 교착상태란 무엇이며, 교착상태가 발생하기 위해서는 어떤 조건이 있어야 하나요?

  > 교착상태(Deadlock)란, 일련의 프로세스들이 각자가 가진 자원을 내어놓지 않고 상대방의 자원을 기다리며 block된 상태를 말한다. 교착상태가 발생하기 위해선 4가지 조건이 필요하다.
  > 1. Mutual exclusion (상호 배제)
  > 동시에 하나의 프로세스만이 자원을 사용할 수 있다.
  > 2. No preemption (비선점)
  > 프로세스는 자원을 스스로 release할 수 있고, 강제로 빼앗기지 않는다.
  > 3. Hold and wait (보유대기)
  > 자원을 가진 프로세스가 다른 자원을 기다릴 때 자신의 자원을 계속 보유하고 있다.
  > 4. Circular wait (순환대기)
  > 자원을 기다리는 프로세스들 사이에 사이클이 형성되어야 한다.

- 교착상태의 해결법은 무엇인가요?

  > 교착 상태의 처리는 크게 네 가지 방법으로 가능하다.  
  > 1. Deadlock Prevention  
  >   Deadlock이 발생하지 않도록 미리 예방하는 것으로, 자원 할당 시 Deadlock의 4가지 필요조건 중 어느 하나가 만족되지 않도록 하는 방식이다.  
  >   Mutual Exclusion에 대해서는 따로 방지하는 방법이 없다.  
  >   No preemption에 대해서는 어떤 자원을 기다려야 하는 경우, 이미 보유한 자원을 빼앗기게 한다. 주로 State를 쉽게 save/restore 할 수 있는 CPU, Memory에 대해서 사용한다.  
  >   Hold and Wait에 대해서는 프로세스 시작 시 모든 필요한 자원을 미리 할당하거나, 자원이 필요할 경우 현재 보유한 자원을 모두 놓고 다시 요청하도록 한다.  
  >   Circular Wait에 대해서는 모든 자원 유형에 할당 순서를 정하고 정해진 순서대로만 자원을 할당하도록 한다.  
  > 2. Deadlock Avoidance  
  >   자원 요청에 대한 부가적인 정보를 이용해서 deadlock의 가능성이 없는 경우(safe)에만 자원을 할당한다. 시스템 state가 원래 state로 돌아올 수 있는 경우에만 자원을 할당한다. 각 자원 타입마다 하나의 인스턴스가 존재하는 경우는 자원 할당 그래프 알고리즘을, 여러 인스턴스가 존재하는 경우는 은행원 알고리즘을 이용할 수 있다.  
  > 3. Deadlock Detection and recovery  
  >   Deadlock 발생은 허용하되 그에 대한 detection 루틴을 두어 deadlock 발견 시 recover하는 방법이다. Single instance per resource type일 때는 자원할당 그래프(or Wait-for 그래프)를 통해 cycle의 존재여부를 확인하여 cycle이 있으면 deadlock이라고 판단한다. Multiple instance per resource type일 때는 Banker's algorithm과 유사하지만, "추가요청 가능 자원 <= 가용 자원" 일 때가 아닌 "현 시점 요청 자원 <= 가용 자원" 일 때 자원을 할당하며, 이때 가용 자원의 갯수에는 현 시점에 요청이 없는 프로세스가 보유하고 있는 자원을 포함하여 산정한다.  
  > 4. Deadlock Ignorance  
  >   Deadlock은 매우 드물게 발생하기 때문에 이에 대한 조치 자체가 더 큰 overhead를 발생시킨다고 판단하여 아무런 조치를 취하지 않는 것이다. 따라서 만약 시스템에 Deadlock이 발생한 경우, 시스템이 비정상적으로 작동하는 것을 사람이 느낀 후 직접 프로세스를 죽이는 등의 방법으로 대처한다. UNIX를 포함한 대부분의 OS가 해당 방식을 채택하고 있다.  

- Banker's algorithm 은 무엇입니까?

  > Deadlock 해결법 중 Deadlock avoidance에서 사용하는 알고리즘으로, 자원의 인스턴스 수가 여러 개일 때 사용하는 알고리즘이다. 추가 요청 가능한 인스턴스의 수(Need, 해당 자원에 대한 최대 사용량 - 현재 보유량)가 이용 가능한 인스턴스의 수(Available)에 충분히 포함되는지를 확인하고 충족이 안된다면 충족이 가능한 프로세스에게 먼저 할당을 하면서 safe state를 유지하도록 한다. 모든 프로세스가 종료될 때까지 이 과정을 반복한다.

- 교착상태와 starvation의 차이는?

  > 교착상태는 프로세스의 상태 중 block 상태일 때 발생하며, 절대 발생하지 않을 이벤트를 무한히 대기한다. 필요한 자원이 공유자원이다. Starvation은 프로세스의 ready 상태일 때 발생하며, 높은 우선순위를 가진 프로세스에 의해 원하는 자원을 계속 선점당하여 무한히 대기하는 것이다. 필요한 자원은 CPU 할당이다.


### ⚡️ Chapter 8. Memory Management

- 메모리 관리에서 페이징와 세그멘테이션에 대해서 설명해 보시오.

  > **페이징(Paging)** 은 logical memory를 동일한 크기의 page들로 분할하고 물리적 메모리에 올리는 Noncontiguous한 메모리 할당 방법이다. 이때 physical memory는 page와 동일한 크기의 frame들로 나누어지며, 각 page는 그에 해당하는 frame의 위치에 저장된다. 외부 단편화는 발생하지 않는다는 장점이 있지만 내부 단편화는 해결하지 못하고, page table을 저장하기 위한 메모리 공간이 더 필요하다는 단점이 있다.  
  > **세그멘테이션(Segmentation)** 은 프로세스의 논리적 메모리를 의미 단위로 분할하여 물리적 메모리에 올리는 Noncontiguous한 메모리 할당 방법이다. Segment는 작게는 프로그램을 구성하는 함수 하나하나일 수 있고, 크게는 프로그램 전체가 될 수도 있다. 세그먼트마다 sharing과 protection을 따로 수행할 수 있어서 효율적이지만, 외부 단편화 문제가 생길 수 있는 단점이 있다.  

- First Fit, Best Fit, Worst Fit에 대해서 설명해 보시오.

  > Dynamic Storage-Allocation 문제로 가변 분할 방식에서 size가 N인 프로세스가 들어가기에 가장 적절한 hole을 찾는 방법을 3가지로 나눈 것이다.  
  > First-Fit : 처음 발견되는 N보다 큰 hole에 바로 할당한다.    
  > Best-Fit : N보다 큰 hole을 다 탐색하고 그 중에 가장 작은 hole에 할당한다. hole들의 리스트가 정렬되어있지 않은 경우 모든 hole을 탐색해야하며, 할당 시 아주 작은 hole들이 여러 개 생성된다는 문제가 있다.   
  > Worst-Fit : N보다 큰 hole을 다 탐색하고 그 중에 가장 큰 hole에 할당한다. Best Fit과 마찬가지로 모든 hole을 탐색해야 하며, 상대적으로 아주 큰 hole들이 생성된다.   
  > First-fit과 Best-fit이 Worst-fit보다 속도와 공간 이용률 측면에서 효과적이다.


- 외부 단편화란? 내부 단편화란?

  > External Fragmentation(외부 단편화) : 프로세스의 크기가 분할(partition)의 크기보다 큰 경우로 메모리에서 남은 총 공간을 계산했을 때 프로세스가 들어갈 공간이 있음에도 공간들의 크기가 작아서 아무 프로그램도 배정되지 않는 공간을 의미한다. 고정분할 방식, 페이징에서 발생할 수 있다.   
  > Internal Fragmentation(내부 단편화) : 프로세스의 크기가 분할(partition)의 크기보다 작은 경우로 분할 내부에서 사용이 되지 않는 공간을 의미한다. 고정분할 방식, 가변분할 방식, 세그멘테이션에서 발생할 수 있다.   


### ⚡️ Chapter 9. Virtual Memory
- 가상 메모리(Virtual Memory)란?  

  > 가상 메모리(Virtual Memory)란, 물리 메모리 크기의 한계를 극복하기 위해 나온 메모리 관리 방법 중 하나로 각 프로그램에 실제 메모리 주소가 아닌 가상의 메모리 주소를 주는 방식을 의미한다. 가상 메모리는 프로세스를 실행할 때, 실행에 필요한 부분만 메모리에 올림으로써 물리 메모리의 용량보다 큰 프로세스를 수행할 수 있게 한다.

- 가상 메모리를 사용할 시 장단점은?  

  > 장점  
  > - 물리 메모리 크기의 제약을 받지않는다.  
  > - CPU 이용률과 처리율이 높아진다.  
  > - 동시에 더 많은 프로그램을 수행할 수 있어 병행성이 높아진다.  
  
  > 단점  
  > - 반복적으로 page fault가 발생하게 되면 프로세스 입출력에 대부분의 시간이 낭비되는 thrashing이 발생할 수 있다.  

- Demand Paging이란?  

  > Demand Paging이란 실제로 필요할 때 해당하는 page를 메모리에 올리는 것이다.대부분의 프로그램은 아주 일부분만 빈번하게 사용되고 나머지는 그렇지 않으므로 프로그램의 전체가 메모리에 항상 있을 필요없이 필요할 때 필요한 부분만 메모리에 올리면서 실행하는 것이 효율적이다. Demand Paging은 valid/invalid bit를 통해 page table에 해당 페이지가 있는지를 확인하고, valid인 경우 해당 메모리에 접근하여 값을 읽어오고, invalid인 경우 page fault를 발생시킨다.
  

- Page fault란?  

  > Demand Paging 방식을 사용할 때 CPU가 프로그램을 실행하면서 필요한 페이지가 물리적 메모리에 없는 경우로, 디스크에서 메모리로 해당 페이지를 가져오는 것이다. 

- 페이지 교체란?  

  > 페이지 교체(Page replacement)란 메모리가 꽉 찬 상태(Free frame이 없는 상태)에서 page fault 발생 시, 메모리에 있는 page 중 가장 쓸모 없는 것을 골라 쫓아내고 그 자리에 필요한 page를 올리는 것을 의미한다.  

- 페이지 교체 알고리즘의 종류와 각각의 특징에 대해 설명해 보시오.  

  > **1. OPT ALgorithm**    
  > Optimal Algorithm은 가장 먼 미래에 참조된 page를 쫓아내는 알고리즘으로 가장 page fault가 적은 알고리즘이다. 실제로 사용되는 것이 아니라 미리 정해진 일련의 input에 대해 실행하는 알고리즘(offline algorithm)으로, 최적의 성능을 보이는 알고리즘이기 때문에 다른 페이지 교체 알고리즘의 성능 상한선 기준이 되는 알고리즘이다.    
  > **2. FIFO(First-In-First-Out) Algorithm**  
  > FIFO Algorithm은 물리적 메모리에 가장 먼저 올라온 페이지를 우선적으로 쫓아내는 알고리즘이다. 메모리를 증가하였음에도 page fault가 오히려 늘어나는 현상(FIFO Anomaly)이 발생할 수 있다.  
  > **3. LRU(Least Recently Used) Algorithm**   
  > LRU Algorithm은 가장 오래 전에 참조된 것을 지우는 알고리즘이다. 시간지역성(temporal locality)을 이용한 알고리즘으로 실제 메모리 관리 알고리즘에서 가장 많이 사용된다. LRU를 linked list로 구현하면 page를 참조하고 지우는 데 시간복잡도는 O(1)이다.  
  > **4. LFU(Least Frequently Used) Algorithm**  
  > LFU Algorithm은 참조 횟수(reference count)가 가장 적은 page를 지우는 알고리즘이다. LRU 처럼 직전 참조 시점만 보는 것이 아니라 장기적인 시간 규모을 보기 때문에 page의 인기도를 좀 더 정확하게 반영할 수 있다. 그러나, 참조 시점의 최근성을 반영하지 못하고 구현이 복잡하다는 특징이 있다. LFU를 Heap으로 구현하면 page를 참조하고 지우는데 시간복잡도는 O(log n)가 된다.  
  > **5. Clock(NUR/Second chance) Algorithm**  
  > Paging System에서 OS는 page fault가 발생했을 때만 관여하기 때문에, 페이지가 이미 메모리에 존재하는 때의 참조 정보를 알 수 없어 LRU, LFU 알고리즘을 사용하는 것은 사실 불가능하다. 따라서 Paging System에서 실제로 사용할 수 있도록 개선된 알고리즘이 Clock Algorithm이다.  
  > Clock Algorithm은 LRU의 근사(approximation) 알고리즘으로, reference bit를 사용해서 쫓아낼 페이지를 선정한다. page들로 구성된 Circular list를 차례대로 지속적으로 탐색하며 Reference bit(해당 페이지가 참조될 때 하드웨어에 의해 1이 되는 bit)를 체크하는데, 1이면 0으로 set한 후 다음으로 이동하고, 0이면 그 페이지를 교체한다.
